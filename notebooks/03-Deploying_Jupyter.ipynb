{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Deploying Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will learn how to:\n",
    "\n",
    " - Configure remote Jupyter deployment.\n",
    " - Deploy Jupyter on a compute node.\n",
    " - Access deployed Jupyter Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import idact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `idact` to path if it's not already installed, for instance if this notebook is executed in a cloned repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitmath\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a wildcard import for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idact import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the environment and the cluster. Make sure to use your cluster name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cluster(pro.cyfronet.pl, 22, plggarstka, auth=AuthMethod.PUBLIC_KEY, key='C:\\\\Users\\\\Maciej/.ssh\\\\id_rsa_6p', install_key=False, disable_sshd=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_environment()\n",
    "cluster = show_cluster(\"hpc\")\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_node = cluster.get_access_node()\n",
    "access_node.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure remote Jupyter deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Jupyter on the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure Jupyter is installed with the Python 3.5+ distribution you intend to use on the cluster. The recommended version is JupyterLab.\n",
    "See [JupyterLab](https://jupyterlab.readthedocs.io/en/stable/getting_started/installation.html), [Jupyter Notebook](https://jupyter.readthedocs.io/en/latest/install.html).\n",
    "\n",
    "If you encounter any problems with deployment, this may be due to some library versions being incompatible. You can try installing frozen versions included with the *idact* repo in `envs/dask_jupyter_tornado.txt`:\n",
    "\n",
    "```\n",
    "pip install -r dask_jupyter_tornado.txt\n",
    "```\n",
    "\n",
    "You may need to add `--user`, if you are using a system Python distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify setup actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's rare that the default Python distribution is the one you want to use for computation.\n",
    "\n",
    "Depending on your setup, you probably need to modify the `PATH` and `PYTHONPATH` environment variables, `source activate` a Conda environment, or perform other specific steps.\n",
    "\n",
    "In order for *idact* to find and execute the proper binaries, you'll need to specify these steps as a list of Bash script lines. Make sure to modify the list below to fit your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.config.setup_actions.jupyter = ['module load plgrid/tools/python-intel/3.6.2']\n",
    "save_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose JupyterLab or Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, JupyterLab is used. If you want to use regular Jupyter Notebook, set the config entry below to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.config.use_jupyter_lab = True\n",
    "save_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allocate node for Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will deploy Jupyter on a single node. Make sure to adjust the `--account` parameter, same as in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-24 00:45:17 INFO: Creating the ssh directory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Nodes([Node(NotAllocated)], SlurmAllocation(job_id=14334261))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = cluster.allocate_nodes(nodes=1,\n",
    "                               cores=2,\n",
    "                               memory_per_node=bitmath.GiB(10),\n",
    "                               walltime=Walltime(minutes=10),\n",
    "                               native_args={\n",
    "                                   '--account': 'intdata'\n",
    "                               })\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-24 00:45:26 INFO: Still pending or configuring...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Nodes([Node(p0260:51704, 2018-11-23 23:55:25.372155+00:00)], SlurmAllocation(job_id=14334261))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.wait()\n",
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the connection, just in case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'p0260'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[0].run('hostname')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the initial setup, Jupyter can be deployed with a single command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JupyterDeployment(8080 -> Node(p0260:51704, 2018-11-23 23:55:25.372155+00:00)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = nodes[0].deploy_notebook()\n",
    "nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the deployment succeeded, you can open the deployed notebook in the browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.open_in_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that there are no issues with the deployed Jupyter Notebook instance. Try to start a kernel and see if it looks stable. Make sure the version of Python you expected is used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the Jupyter deployment failed for some reason, you will find the `jupyter` command log in the debug log file: `idact.log`.\n",
    "\n",
    "If your last failure is a timeout, e.g. `2018-11-12 22:14:00 INFO: Retried and failed: config.retries(...)`, check out the tutorial `07. Adjusting timeouts` if you believe the timeout might be too restrictive for your cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you're done, you can cancel the deployment by calling `cancel`, though it will be killed anyway when the node allocation ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-24 00:46:02 INFO: Cancelling Jupyter deployment.\n"
     ]
    }
   ],
   "source": [
    "nb.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, the following will just close the tunnel, without attempting to kill Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.cancel_local()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancel the allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to cancel an allocation if you're done with it early, in order to minimize the CPU time you are charged for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.running()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-24 00:46:12 INFO: Cancelling job 14334261.\n"
     ]
    }
   ],
   "source": [
    "nodes.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.running()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook, we will deploy a Dask.distributed scheduler and workers on several compute nodes, and browse their dashboards."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
