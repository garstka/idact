{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09a. Demo analysis - local part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook and its remote counterpart `09b`, you will learn how to:\n",
    "\n",
    " - Download a large quantity of CSV data for analysis.\n",
    " - Load the data using Dask on the cluster.\n",
    " - Convert the data to a more suitable format: Apache Parquet.\n",
    " - Load the data from Parquet.\n",
    " - Perform a simple data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install an SSH client\n",
    "\n",
    "For this tutorial, we will need an SSH client to connect to the cluster. It's likely you already have OpenSSH on Linux and Windows 10. PuTTY on Windows will work too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import idact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's recommended that *idact* is installed with *pip*. Alternatively, make sure the dependencies are installed: `pip install -r requirements.txt`, and add *idact* to path, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a wildcard import for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idact import *\n",
    "import bitmath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the environment and the cluster. Make sure to use your cluster name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cluster(pro.cyfronet.pl, 22, plggarstka, auth=AuthMethod.PUBLIC_KEY, key='C:\\\\Users\\\\Maciej/.ssh\\\\id_rsa_6p', install_key=False, disable_sshd=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_environment()\n",
    "cluster = show_cluster(\"hpc\")\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_node = cluster.get_access_node()\n",
    "access_node.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the data to analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of open source datasets available online for free. In many cases, you need to pay for the bandwidth though, especially if the dataset is more that a few gigabytes. In some cases, especially when the data is from government agencies, it's available fully free of charge.\n",
    "\n",
    "I will use the New York City Taxi & Limousine Commission Trip Record Data (yellow) for years 2010-2014, available [here](http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml).\n",
    "Since 2015, there was a slight change in formatting, so we'll not worry about the newer data for now.\n",
    "\n",
    "For the years we're interested in, there is a CSV file for each month, so we have 12\\*5=60 CSV files, with the total size of 143GiB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will download the data straight to the cluster, by logging in to a compute node through SSH. \n",
    "\n",
    "Let's allocate the node. We will download two years at a time, so let's get 24 cores for an hour, though the download shouldn't take that long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-02 05:18:48 INFO: Installing key in '.ssh/authorized_keys.idact' for access to compute nodes.\n",
      "2018-12-02 05:18:48 INFO: Creating the ssh directory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Nodes([Node(NotAllocated)], SlurmAllocation(job_id=14399244))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = cluster.allocate_nodes(nodes=1,\n",
    "                               cores=24,\n",
    "                               memory_per_node=bitmath.GiB(120),\n",
    "                               walltime=Walltime(hours=1),\n",
    "                               native_args={\n",
    "                                   '--account': 'intdata',\n",
    "                                   '--partition': 'plgrid-testing'\n",
    "                               })\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-02 05:18:56 INFO: Still pending or configuring...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Nodes([Node(p0007:58019, 2018-12-02 05:18:54.856900+00:00)], SlurmAllocation(job_id=14399244))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.wait()\n",
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's log in to the node by creating a tunnel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ssh -i \"C:\\Users\\Maciej/.ssh\\id_rsa_6p\" -p 58019 plggarstka@localhost"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tunnel = nodes[0].tunnel_ssh()\n",
    "tunnel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have OpenSSH, the command printed above should work. Otherwise, you need to copy the key path, host and port to PuTTY."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once on the node, let's pick a directory to download the data into. Depending on the cluster and available resources, you may have a team storage area for persistent data.\n",
    "\n",
    "On my cluster, there is also a temporary (30 day) personal storage determined by the environment variable `$SCRATCH`, which I will use for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a directory for the data:\n",
    "```\n",
    "cd $SCRATCH && mkdir taxi && cd taxi\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, download the data. I downloaded the CSV files using wget in batches of 24."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-01.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-02.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-03.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-04.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-05.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-06.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-07.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-08.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-09.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-10.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-11.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2014-12.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2013-01.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2013-02.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2013-03.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2013-04.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2013-05.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2013-06.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2013-07.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2013-08.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2013-09.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2013-10.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2013-11.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2013-12.csv &\n",
    "\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2012-01.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2012-02.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2012-03.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2012-04.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2012-05.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2012-06.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2012-07.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2012-08.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2012-09.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2012-10.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2012-11.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2012-12.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2011-01.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2011-02.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2011-03.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2011-04.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2011-05.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2011-06.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2011-07.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2011-08.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2011-09.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2011-10.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2011-11.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2011-12.csv &\n",
    "\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2010-01.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2010-02.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2010-03.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2010-04.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2010-05.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2010-06.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2010-07.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2010-08.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2010-09.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2010-10.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2010-11.csv &\n",
    "wget https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2010-12.csv &\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install fastparquet on the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need `fastparquet` on the cluster, so while you have the access to the compute node, install \n",
    "it in your Python environment, e.g.:\n",
    "```\n",
    "pip install fastparquet --user\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancel the download node allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're done, so we won't need the node anymore. Let's close the ssh tunnel and cancel the allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-02 05:19:24 INFO: Cancelling job 14399244.\n"
     ]
    }
   ],
   "source": [
    "tunnel.close()\n",
    "nodes.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allocate nodes for conversion from CSV to Apache Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's allocate a few nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-02 05:19:30 INFO: Installing key in '.ssh/authorized_keys.idact' for access to compute nodes.\n",
      "2018-12-02 05:19:30 INFO: Creating the ssh directory.\n"
     ]
    }
   ],
   "source": [
    "nodes = cluster.allocate_nodes(nodes=6,\n",
    "                               cores=24,\n",
    "                               memory_per_node=bitmath.GiB(120),\n",
    "                               walltime=Walltime(hours=1),\n",
    "                               native_args={\n",
    "                                   '--account': 'intdata',\n",
    "                                   '--partition': 'plgrid-testing'\n",
    "                               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-02 05:22:56 INFO: Still pending or configuring...\n",
      "2018-12-02 05:23:00 INFO: Still pending or configuring...\n",
      "2018-12-02 05:23:05 INFO: Still pending or configuring...\n",
      "2018-12-02 05:23:09 INFO: Still pending or configuring...\n",
      "2018-12-02 05:23:14 INFO: Still pending or configuring...\n",
      "2018-12-02 05:23:18 INFO: Still pending or configuring...\n",
      "2018-12-02 05:23:22 INFO: Still pending or configuring...\n",
      "2018-12-02 05:23:26 INFO: Still pending or configuring...\n",
      "2018-12-02 05:23:31 INFO: Still pending or configuring...\n",
      "2018-12-02 05:23:35 INFO: Still pending or configuring...\n",
      "2018-12-02 05:23:39 INFO: Still pending or configuring...\n",
      "2018-12-02 05:23:45 INFO: Still pending or configuring...\n",
      "2018-12-02 05:23:52 INFO: Still pending or configuring...\n",
      "2018-12-02 05:23:58 INFO: Still pending or configuring...\n",
      "2018-12-02 05:24:04 INFO: Still pending or configuring...\n",
      "2018-12-02 05:24:11 INFO: Still pending or configuring...\n",
      "2018-12-02 05:24:18 INFO: Still pending or configuring...\n",
      "2018-12-02 05:24:23 INFO: Still pending or configuring...\n",
      "2018-12-02 05:24:29 INFO: Still pending or configuring...\n",
      "2018-12-02 05:24:35 INFO: Still pending or configuring...\n",
      "2018-12-02 05:24:40 INFO: Still pending or configuring...\n",
      "2018-12-02 05:24:44 INFO: Still pending or configuring...\n",
      "2018-12-02 05:24:48 INFO: Still pending or configuring...\n",
      "2018-12-02 05:24:52 INFO: Still pending or configuring...\n",
      "2018-12-02 05:24:56 INFO: Still pending or configuring...\n",
      "2018-12-02 05:25:01 INFO: Still pending or configuring...\n",
      "2018-12-02 05:25:05 INFO: Still pending or configuring...\n",
      "2018-12-02 05:25:10 INFO: Still pending or configuring...\n",
      "2018-12-02 05:25:15 INFO: Still pending or configuring...\n",
      "2018-12-02 05:25:19 INFO: Still pending or configuring...\n",
      "2018-12-02 05:25:23 INFO: Still pending or configuring...\n",
      "2018-12-02 05:25:27 INFO: Still pending or configuring...\n",
      "2018-12-02 05:25:31 INFO: Still pending or configuring...\n",
      "2018-12-02 05:25:35 INFO: Still pending or configuring...\n",
      "2018-12-02 05:25:39 INFO: Still pending or configuring...\n",
      "2018-12-02 05:25:46 INFO: Still pending or configuring...\n",
      "2018-12-02 05:25:51 INFO: Still pending or configuring...\n",
      "2018-12-02 05:25:57 INFO: Still pending or configuring...\n",
      "2018-12-02 05:26:03 INFO: Still pending or configuring...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Nodes([Node(p0109:59529, 2018-12-02 05:26:06.298927+00:00),Node(p0110:60911, 2018-12-02 05:26:06.298927+00:00),Node(p0111:58340, 2018-12-02 05:26:06.298927+00:00),Node(p0112:39446, 2018-12-02 05:26:06.298927+00:00),Node(p0113:36112, 2018-12-02 05:26:06.298927+00:00),Node(p0114:52334, 2018-12-02 05:26:06.298927+00:00)], SlurmAllocation(job_id=14399245))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.wait()\n",
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy a Jupyter Notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JupyterDeployment(8080 -> Node(p0109:59529, 2018-12-02 05:26:06.298927+00:00)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = nodes[0].deploy_notebook()\n",
    "nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, Dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-02 05:26:46 INFO: Deploying Dask on 6 nodes.\n",
      "2018-12-02 05:26:46 INFO: Connecting to p0109:59529 (1/6).\n",
      "2018-12-02 05:26:46 INFO: Connecting to p0110:60911 (2/6).\n",
      "2018-12-02 05:26:48 INFO: Connecting to p0111:58340 (3/6).\n",
      "2018-12-02 05:26:54 INFO: Connecting to p0112:39446 (4/6).\n",
      "2018-12-02 05:27:01 INFO: Connecting to p0113:36112 (5/6).\n",
      "2018-12-02 05:27:03 INFO: Connecting to p0114:52334 (6/6).\n",
      "2018-12-02 05:27:05 INFO: Deploying scheduler on the first node: p0109.\n",
      "2018-12-02 05:28:24 INFO: Retried and failed: config.retries[Retry.OPEN_TUNNEL].{count=3, seconds_between=5}\n",
      "2018-12-02 05:28:24 ERROR: Failure: Adding last hop.\n",
      "2018-12-02 05:28:50 INFO: Checking scheduler connectivity from p0109 (1/6).\n",
      "2018-12-02 05:28:50 INFO: Checking scheduler connectivity from p0110 (2/6).\n",
      "2018-12-02 05:28:50 INFO: Checking scheduler connectivity from p0111 (3/6).\n",
      "2018-12-02 05:28:50 INFO: Checking scheduler connectivity from p0112 (4/6).\n",
      "2018-12-02 05:28:50 INFO: Checking scheduler connectivity from p0113 (5/6).\n",
      "2018-12-02 05:28:51 INFO: Checking scheduler connectivity from p0114 (6/6).\n",
      "2018-12-02 05:28:51 INFO: Deploying workers.\n",
      "2018-12-02 05:28:51 INFO: Deploying worker 1/6.\n",
      "2018-12-02 05:29:06 INFO: Deploying worker 2/6.\n",
      "2018-12-02 05:29:15 INFO: Deploying worker 3/6.\n",
      "2018-12-02 05:29:25 INFO: Deploying worker 4/6.\n",
      "2018-12-02 05:29:41 INFO: Deploying worker 5/6.\n",
      "2018-12-02 05:30:18 INFO: Deploying worker 6/6.\n",
      "2018-12-02 05:30:52 INFO: Validating worker 1/6.\n",
      "2018-12-02 05:30:52 INFO: Validating worker 2/6.\n",
      "2018-12-02 05:30:52 INFO: Validating worker 3/6.\n",
      "2018-12-02 05:30:52 INFO: Validating worker 4/6.\n",
      "2018-12-02 05:30:52 INFO: Validating worker 5/6.\n",
      "2018-12-02 05:30:52 INFO: Validating worker 6/6.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DaskDeployment(scheduler=tcp://localhost:53769/tcp://172.20.64.109:46289, workers=6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = deploy_dask(nodes)\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push the nodes and Dask deployment, because we'll use them on the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-02 05:30:52 INFO: Clearing deployments.\n",
      "2018-12-02 05:30:55 INFO: Pushing deployment: Nodes([Node(p0109:59529, 2018-12-02 05:26:06.298927+00:00),Node(p0110:60911, 2018-12-02 05:26:06.298927+00:00),Node(p0111:58340, 2018-12-02 05:26:06.298927+00:00),Node(p0112:39446, 2018-12-02 05:26:06.298927+00:00),Node(p0113:36112, 2018-12-02 05:26:06.298927+00:00),Node(p0114:52334, 2018-12-02 05:26:06.298927+00:00)], SlurmAllocation(job_id=14399245))\n",
      "2018-12-02 05:31:00 INFO: Pushing deployment: DaskDeployment(scheduler=tcp://localhost:53769/tcp://172.20.64.109:46289, workers=6)\n"
     ]
    }
   ],
   "source": [
    "cluster.clear_pushed_deployments()\n",
    "cluster.push_deployment(nodes)\n",
    "cluster.push_deployment(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the Dask Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the scheduler dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://localhost:53769\n",
       "  <li><b>Dashboard: </b><a href='http://localhost:33300/status' target='_blank'>http://localhost:33300/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>6</li>\n",
       "  <li><b>Cores: </b>144</li>\n",
       "  <li><b>Memory: </b>773.09 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://172.20.64.109:46289' processes=6 cores=144>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = dd.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is nothing interesting there for now, but we will observe what happens when we load the data later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also browse the dashboards for workers as well, if you want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://localhost:33300/status',\n",
       " 'http://localhost:55762/main',\n",
       " 'http://localhost:43330/main',\n",
       " 'http://localhost:60271/main',\n",
       " 'http://localhost:55581/main',\n",
       " 'http://localhost:59782/main',\n",
       " 'http://localhost:51605/main']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd.diagnostics.addresses\n",
    "# dd.diagnostics.open_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need the client anymore here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy notebook `09b` to the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drag and drop `09b-Demo_analysis_-_remote_part.ipynb` to the deployed notebook, and open it there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.open_in_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow the instructions in notebook `09b`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the instructions until you are referred back to this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancel the allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to cancel an allocation if you're done with it early, in order to minimize the CPU time you are charged for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.running()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes.running()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
