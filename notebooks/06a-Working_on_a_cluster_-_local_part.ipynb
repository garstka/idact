{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06a. Working on a cluster - local part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook and its remote counterpart `06b`, you will learn how to:\n",
    "\n",
    " - Synchronize deployments between the local machine and a notebook running on the cluster.\n",
    " - Perform simple computations using the Dask deployment on a deployed notebook.\n",
    " - Clear synchronized deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import idact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add `idact` to path if it's not already installed, for instance if this notebook is executed in a cloned repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitmath\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a wildcard import for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from idact import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the environment and the cluster. Make sure to use your cluster name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cluster(pro.cyfronet.pl, 22, plggarstka, auth=AuthMethod.PUBLIC_KEY, key='C:\\\\Users\\\\Maciej/.ssh\\\\id_rsa_6p', install_key=False, disable_sshd=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_environment()\n",
    "cluster = show_cluster(\"hpc\")\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_node = cluster.get_access_node()\n",
    "access_node.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allocate nodes, deploy Jupyter and Dask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be working with Dask on a Jupyter Notebook deployed on the cluster. Make sure to adjust `--account`, same as in previous notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-24 15:15:57 INFO: Creating the ssh directory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Nodes([Node(NotAllocated),Node(NotAllocated),Node(NotAllocated)], SlurmAllocation(job_id=14335314))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = cluster.allocate_nodes(nodes=3,\n",
    "                               cores=2,\n",
    "                               memory_per_node=bitmath.GiB(10),\n",
    "                               walltime=Walltime(minutes=20),\n",
    "                               native_args={\n",
    "                                   '--account': 'intdata'\n",
    "                               })\n",
    "nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nodes([Node(p0276:52339, 2018-11-24 14:36:03.264418+00:00),Node(p0281:56749, 2018-11-24 14:36:03.264418+00:00),Node(p0284:34760, 2018-11-24 14:36:03.264418+00:00)], SlurmAllocation(job_id=14335314))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.wait()\n",
    "nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy a notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JupyterDeployment(8080 -> Node(p0276:52339, 2018-11-24 14:36:03.264418+00:00)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = nodes[0].deploy_notebook()\n",
    "nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy Dask on all three nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-24 15:16:27 INFO: Deploying Dask on 3 nodes.\n",
      "2018-11-24 15:16:27 INFO: Connecting to p0276:52339 (1/3).\n",
      "2018-11-24 15:16:27 INFO: Connecting to p0281:56749 (2/3).\n",
      "2018-11-24 15:16:29 INFO: Connecting to p0284:34760 (3/3).\n",
      "2018-11-24 15:16:31 INFO: Deploying scheduler on the first node: p0276.\n",
      "2018-11-24 15:16:43 INFO: Checking scheduler connectivity from p0276 (1/3).\n",
      "2018-11-24 15:16:43 INFO: Checking scheduler connectivity from p0281 (2/3).\n",
      "2018-11-24 15:16:43 INFO: Checking scheduler connectivity from p0284 (3/3).\n",
      "2018-11-24 15:16:43 INFO: Deploying workers.\n",
      "2018-11-24 15:16:43 INFO: Deploying worker 1/3.\n",
      "2018-11-24 15:16:54 INFO: Deploying worker 2/3.\n",
      "2018-11-24 15:17:05 INFO: Deploying worker 3/3.\n",
      "2018-11-24 15:17:17 INFO: Validating worker 1/3.\n",
      "2018-11-24 15:17:17 INFO: Validating worker 2/3.\n",
      "2018-11-24 15:17:17 INFO: Validating worker 3/3.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DaskDeployment(scheduler=tcp://localhost:46388/tcp://172.20.65.21:46388, workers=3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = deploy_dask(nodes)\n",
    "dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synchronize the deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may be useful to access the allocated nodes, or any other deployment above from another notebook.\n",
    "\n",
    "In particular, we need to access the Dask deployment from the notebook that was deployed on the cluster, in order to perform computations.\n",
    "\n",
    "Synchronizing a deployment involves *pushing* it first, and the *pulling* on another notebook.\n",
    "\n",
    "Let's push the allocation first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-24 15:17:17 INFO: Pushing deployment: Nodes([Node(p0276:52339, 2018-11-24 14:36:03.264418+00:00),Node(p0281:56749, 2018-11-24 14:36:03.264418+00:00),Node(p0284:34760, 2018-11-24 14:36:03.264418+00:00)], SlurmAllocation(job_id=14335314))\n"
     ]
    }
   ],
   "source": [
    "cluster.push_deployment(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-24 15:17:25 INFO: Pushing deployment: JupyterDeployment(8080 -> Node(p0276:52339, 2018-11-24 14:36:03.264418+00:00)\n"
     ]
    }
   ],
   "source": [
    "cluster.push_deployment(nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally Dask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-24 15:17:33 INFO: Pushing deployment: DaskDeployment(scheduler=tcp://localhost:46388/tcp://172.20.65.21:46388, workers=3)\n"
     ]
    }
   ],
   "source": [
    "cluster.push_deployment(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will pull the deployments on the remote notebook in a moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy notebook `06b` to the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drag and drop `06b-Working_on_a_cluster_-_remote_part.ipynb` to the deployed notebook, and open it there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.open_in_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow the instructions in notebook `06b`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the instructions until you are referred back to this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Dask Dashboards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always take a look how your computations look on the dashboards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://localhost:46388\n",
       "  <li><b>Dashboard: </b><a href='http://localhost:47991/status' target='_blank'>http://localhost:47991/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>3</li>\n",
       "  <li><b>Cores: </b>6</li>\n",
       "  <li><b>Memory: </b>32.21 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://172.20.65.21:46388' processes=3 cores=6>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = dd.get_client()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd.diagnostics.open_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear synchronized deployments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deployments are cleared automatically if they are expired or cancelled. They can also be cleared manually by  running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-24 15:20:11 INFO: Clearing deployments.\n"
     ]
    }
   ],
   "source": [
    "cluster.clear_pushed_deployments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancel Dask and Jupyter deployments (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-24 15:20:13 INFO: Cancelling Jupyter deployment.\n"
     ]
    }
   ],
   "source": [
    "nb.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-24 15:20:20 INFO: Cancelling worker deployment on p0284.\n",
      "2018-11-24 15:20:26 INFO: Cancelling worker deployment on p0281.\n",
      "2018-11-24 15:20:33 INFO: Cancelling worker deployment on p0276.\n",
      "2018-11-24 15:20:40 INFO: Cancelling scheduler deployment on p0276.\n"
     ]
    }
   ],
   "source": [
    "dd.cancel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancel the allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to cancel an allocation if you're done with it early, in order to minimize the CPU time you are charged for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.running()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-24 15:20:49 INFO: Cancelling job 14335314.\n"
     ]
    }
   ],
   "source": [
    "nodes.cancel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.running()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook we will take a look on how to adjust deployment timeouts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
